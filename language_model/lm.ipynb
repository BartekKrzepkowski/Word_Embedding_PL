{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "random_seed = 42\n",
    "\n",
    "from models import LM, LMLoss\n",
    "from data import LM_Dataset\n",
    "from trainer_ml import LMTrainer\n",
    "from utils import loaders_from_dataset, visualize_embeddings, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LM_Dataset('datasets/wmt14_en_ger/train _small.en')\n",
    "loaders = loaders_from_dataset(dataset, batch_size=32, val_perc_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "model = LM(vocab_size=len(dataset.Ind2word), emb_dim=50, rnn=torch.nn.GRU)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "params_trainer = {\n",
    "    'model': model,\n",
    "    'loaders': loaders,\n",
    "    'criterion': LMLoss(),\n",
    "    'optim': optim,\n",
    "    'val_step': 5,\n",
    "    'scheduler': torch.optim.lr_scheduler.CosineAnnealingLR(optim, epochs),\n",
    "    'verbose': False,\n",
    "    'device': device,\n",
    "#     'params_clearml': params_clearml,\n",
    "    'is_tensorboard': True\n",
    "}\n",
    "\n",
    "trainer = LMTrainer(**params_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-combat",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.loop(0, epochs, exp_name='GRU_wmt2014_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Ind = {word: i for i, word in dataset.Ind2word.items()}\n",
    "\n",
    "chosen_words = [\n",
    "    \"świetny\", \"głupi\", \"wspaniały\", \"spoko\", \"ekstra\",\n",
    "    \"słodki\", \"nudny\",   \"zły\", \n",
    "    \"artyleria\", \"generał\", 'porucznik', \"sierżant\", \"wojsko\",\n",
    "#     \"dobrze\"\n",
    "] \n",
    "chosen_idxs = [word2Ind[word] for word in chosen_words]\n",
    "\n",
    "visualize_embeddings(model.embs.weight.detach().cpu().numpy(), chosen_idxs, dataset.Ind2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-liability",
   "metadata": {},
   "source": [
    "## Length of sentence distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len = np.array([len(sent) for sent in dataset.indexed_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sent_len, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent_len.mean(), sent_len.std(), sent_len.min(), sent_len.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-facial",
   "metadata": {},
   "source": [
    "Uwagi:\n",
    "- Czy nie powinienem brac P(x_t|x_1, x_2,...,x_{t-1}) dopiero od pewnego t > 2? (t > 5)?\n",
    "- Zbudować ewaluacje, \n",
    "- Poprawić trainera na guthubie (os.makedirs, .pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LM(vocab_size=len(dataset.Ind2word), emb_dim=50, rnn=torch.nn.LSTM)\n",
    "load_model(model, 'data/LSTM/2022-04-01_00-20-06/checkpoints/_epoch_199.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-tracy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
